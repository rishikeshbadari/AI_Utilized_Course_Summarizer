all right let's get started welcome back to double06 today we are doing some of the coolest data structures we will see in this class maybe some of the coolest data structures ever binary trees uh you've certainly seen trees in many forms uh in the past including in this class we've talked to use trees as a lower bound tool for uh in the decision tree model but this lecture and the next lecture we're going to build one data structure that is almost superior to all data structures we have seen and can do almost anything really fast first recall all the data structures we've seen so far arrays linked lists dynamic arrays sorted arrays hash tables and the two sets of operations we're interested in supporting the two interfaces one was sequences where we're maintaining items in a specified order we want to be able to insert an item right after another item or delete an item in the middle of the list and always be able to access the ith item we haven't seen any good data structures for that problem we we're really good at inserting and deleting at the beginning or the end of the sequence but we haven't seen anything that's efficient at ins inserting in the middle of the list or deleting in the middle of the list linked list you can't even get to the middle in less than linear time uh array you can get to the middle but if you make any changes you have to do this shift which is very expensive so today or sorry next lecture for the first time we will see all of those operations efficient i'll mention our goal where efficient means logarithmic so we're not quite as good as linked lists and dynamic arrays at inserting and deleting at the ends those there that we achieve constant or constant amortized time but up to this log factor we're going to get the best of all worlds where we can solve all the things all the operations that don't build or iterate through the entire structure that of course takes linear time but we can do all the others in logarithmic time for sets sets were maintained maintaining a bunch of items which have intrinsic keys and we want to search by key so hash tables are great if you're only doing exact searches if you want to find a key and get yes or no is it in there and if it's in there give me the item that's what python dictionaries do and they're great at inserting and deleting but they're really bad at find previous and find next this is a the unsuccessful case if i search for a key and it's not in my structure i would like to know more than just the answer no i'd like to know what the previous and next items that are actually in the structure so what are my nearest matches when i search by key that's a natural query and the only data structure we have that's good at it is a sorted array because binary search gives this to us if we search for a key by binary search and we don't find it the position that we end up at is right between the previous and next one but of course sorted arrays are terrible for dynamic operations we don't know how to maintain we can't maintain a sorted array without any gaps when we're doing insertions and deletions in some sense today and next class binary trees let us represent a sorted order or in general an order of items dynamically and still allow us to do very fast things like get out of i and find previous of the key so that's our goal we're not going to quite get to this goal today we're going to get an incomparable thing called the height of the tree and then on thursday we'll be able to finish and achieve this goal today is just in service to that goal so what is a binary tree let me draw an example and then define it more precisely mathematicians will call this a rooted binary tree because in case you've seen that in o42 say here is a picture so this is an example of a binary tree it has a bunch of nodes which we're drawing in circles it has items in the nodes which were i'm writing as letters here so this is item a item b item c and it has these links between them this is like linked lists but in general a node x is going to have a parent pointer a left child left pointer and a right child right pointer and it also has an item inside of it so i'm going to talk about node.left is a pointer to the left the node down here node.right node.parent node.item gives me so if i look at the node a its item is a so let me draw for you some examples okay the parent of a is nothing so we call a the root node there's going to be a unique node that has no parent it's uh sad to have no parents but there you go then we have node b which whose parent is a node c is parent its apparent is a node d its parent is b node e its parent is b and node f its parent is d alphabetical order here happens to be ordered by parent then we have left pointers i'll just do a few of them so left pointer of a is b right pointer of a sorry b the node uh these should all be notes i'm circling for nodes and just writing the letter for the item make it clear that those are different things uh the right pointer for a is c left pointer for b is d right pointer for b is e and so on okay so in other words each of these lines is a bi-directional pointer uh in this direction it's the parent direction in this direction it's left in this case because it's bidirectional we don't draw the arrows we just draw undirected lines okay this is in general what a binary tree looks like a key invariant is that if you take a node and say go to its left pointer left child and then go to that node's parent this should be the same as node right so that's just saying these are in parent is always the inverse of a left or right operation this is also true for write okay and that's a binary tree now the intuition of what's going on here is you could you could say it's we're inspired by a linked list linked list had a very similar structure maybe an item or there's a node it had an item in it and it had a next pointer and it had a previous pointer so in some sense what we're if it's doubly linked we had a previous pointer it was singly linked we only had a next pointer and if you think about the limits of linked lists especially singly linked lists if you just have one pointer per node you can only build a list and so the result is uh you know this this node is going to have depth linear depth means how many pointers do i have to follow to get here from the root of the structure which for linked lists was the head it was doubly linked okay i can have a head and a tail and i can put bi-directions on here but then still the middle item has depth linear so there's no way to get there in less than linear time with binary trees because we use two types of next pointers left and right we can build a tree and we know trees in general have logarithmic can have logarithmic height and so it's possible in a tree to get to any node starting from the root in only log n traversals so that's the intuition of what's going on now today we're going to talk about the height of a tree so let me define i'm going to need a couple definitions here subtree and height of a node uh so a tree decomposes into sub trees so for example the subtree rooted at b or the subtree of b is this portion of the tree so it's that node and all of the descendants of this node so because we have parents and children we can generalize in the familial tree sense we can talk about ancestors of a node so the ancestors of f are its parent its grandparents its great grandparents and so on together all of these are called ancestors it's a it doesn't quite correspond to familiar trees because familial trees you have two parents here you only have a unique parent or the poor root has no parent we also talk about it's like mixed metaphors leaves of the tree these are people with no children parents will complain about this but many like many of us in this room we have no children yet so we were called leaves you can tell your parents hey i'm just a leaf you know blowing in the wind so uh you know like this it's so many mixed metaphors but we always draw trees downwards like the root structure of a tree yet we call the ends of the roots leaves which is upside down anyway that's trees for you lots of entertaining analogies okay but ancestors are useful descendants are also useful so the descendants of b are all of its children and all of its grandchildren and all the way down but just within the subtree so subtree of x consists of x and its descendants and we think of x being the root of that subtree so we're kind of forgetting about everything outside of the sub tree when we talk about sub tree of x let's talk about the depth of a node depth of the node is i guess the number of its ancestors right um but way i usually think of it is the number of number of edges and in the path from x up to the root so every node has a unique path that goes upwards until it can't go up anymore so the depth of e is two because there are two edges uh one two in the path from the root a to e so maybe i'll write some depths uh depth of e is two depth of these guys is one depth of the root is zero two three so those are depth i'm going to clean this up a little bit so we can focus on the image all right height so depth is measuring downwards because we you know if you imagine depth within water this is uh the surface of the water and then we measure how deep you are from the surface height is in the reverse direction we're going to measure from the leaf level up because leaves are the bottom of the tree so height of a node is going to be the number of edges in the longest downward path okay which is the same thing as the maximum depth of a node in x's subtree let's do height in red so uh how long is the longest path from f to a leaf well f is a leaf so all leaves have depth zero sorry height zero get it backwards um d here it's so there are two ways to go down this doesn't go to a leaf uh this one goes to a leaf and its height is zero so this height is one there's one edge to a leaf here b has two leaves it can get to we take the longest one so that's length two a similarly has height three okay so height we measure upward depth we measure downward well one thing we care about uh is just the height of the overall tree uh which is the height of the root and i'm going to call that h because we're going to use it a lot and what we're going to achieve today is all of these running times instead of being log n they're going to be order h so today our goal is to get all the operations we care about in order h type and then next lecture we're going to guarantee that h is always log n and then we'll get log n time so we need to do a bunch of work to achieve log n today we'll do the work that's all the tree manipulation and as long as your tree is nice and shallow it doesn't have high height if it has logarithmic height everything will be log n of course there are trees that are really bad right we can have a tree a tree like this which is basically a linked list where we only use right pointers and all the left pointers are none so there are height there are trees that are very high have high height um we want to avoid these but we won't worry about that till next lecture question what is the height of node c height of node c is zero because the length of the longest path the number of edges in the longest downward path is zero yeah we're counting edges not vertices uh yeah so the height of the tree is of course just the depth the maximum depth i think that's right so the height here is three and the maximum depth is this terribly drawn three so these happen to correspond in the maximum case but we use height to always mean maximum and so that's why we talk about the height of the tree depth of the tree is not defined just depths of notes okay um how do we use these trees to represent either a sequence or a set uh i claim that there is a natural order in trees called the traversal order of nodes or items and the tree so i'm going to define a particular order uh say in this example let's do the example first the traversal order is going to be f d b e a c i feel like i'm in music class this is my guitar or something but it's not i hope um if it is a coincidence so what is this order what i'd like to do is um recursively define an order where the root of the tree is somewhere in the middle and everything in the left subtree is left earlier in the order than the root and everything in the right subtree is later so you can see here c comes after a and then all the other nodes come before a and recursively if i look at a node b this node b which appears over here e is to the right of it but it's this is all to the left of a so e is between b and a would be on the left and then f and d are to the left of that and again f comes before d because f is in the left subtree of d okay so we say for every node the nodes in x dot left are before x and the nodes in x dot right are come after x and this uniquely defines an order called a traversal order it's also called the in-order traversal order it's called in order because it's in the traversal order so it's very circular but you may have seen inorder traversal this is the same thing there's a very simple algorithm for computing this if i want to iterate uh let's call this yeah if i want to iterate all the nodes within a subtree x rooted by x i just iterate on all of the nodes in the left subtree then i output x itself then i iterate on all the nodes in the right subtree okay you may have seen that algorithm before this is just another way to codify the same thing the result is all the nodes within a subtree appear continuously with no interruptions and then the parent parent's going to come before after depending on whether it's the left or right child okay so and now it's just a matter of connecting the dots because we're representing an order and for sequence that is going to be the sequence order if we want to store n items x0 through x1 we're going to build some kind of tree we're going to put x0 here x1 here x2 here x3 here x4 here x5 here you can see i'm very used to dealing with traversal orders it takes a little while uh you could also see it here we're going to put x1 on this node x2 sorry x0 here x1 here x2 here and so on that's the same order that i gave okay that's for sequences for sets that order is just going to be the sorted order and we're going to be effectively representing the sorted order of keys say increasing but before we get to that let's talk about different operations we can do just playing around with traversal order and then we're going to use these to build the sequence and set operations that we care about so first operation i'll call subtree first seems appropriate that it's called first it's the first one so given a node which i'll call node uh this defines a subtree which usually we draw subtrees as triangles hanging off of the node so here i would write x and then there's some subtree of all the descendants of x so with subtree first i would like to say among all the nodes in this subtree which comes first in traversal order so just restricting to that subtree so tree of that so where is it in this tree uh note is actually part of many sub trees good question uh f f is in its own in the sub tree of f uh f is also in the subtree of d f is in the sub tree of b like i drew f is in the subtree of a it's in the subtree of exactly its ancestors but in this operation when we define node our node only defines one sub-tree it is the root of only one sub-tree and that's the sub-tree we're talking about and then i want to know among all those nodes which includes node itself and other things uh which one comes first in this traversal order this is like practice with traversal orders so where should i look for this node yeah the leftmost leaf in the picture it's here but pictures can be deceiving we just want to go left as much as possible when i say go left i mean this iteration node equals node.left you just look at our definition all the nodes on the left come before x and all the nodes in the right so it's got to be in the left subtree if there is one uh of course we can't do this forever so say until we would fall off the tree which means uh node is none okay but we stopped uh before that would happen so this is like uh the directions like oh you keep driving until you see the store and it's the block right before that it's like well that's not very helpful so uh you keep iterating node equals no dot left until node becomes none and then you undo one step okay you all know how to program that it's not hard um so that last non-none node which might actually be the root it might be node maybe it has no left children but in that case i claim node is the very first in its in its subtree traversal order because if there are no nodes in the left that come before x then x is actually first okay and that so that's it uh return node so i'm modifying node in place here and the very last one before i hit none that's the minimum that's the first item in the traversal order similarly you can define subtree last okay let's do a more interesting one successor node so in this case i want to know what is the next after node in the overall tree's traversal order okay here i was restricting to uh a single sub tree now i'm thinking about the entire tree in the entire traversal order and given a node i want to know which one comes next call this the successor i feel like i should make some kind of royal family joke now but i don't know how um so every node has a unique successor let's do let's do some examples so we can start with f the successor of f if we just index into this list the successor is d okay successor of d is b successor b is ease okay it's very easy to read successors off when i have the traversal order written down but let's think about how to do it in the tree okay uh let's see there are going to be two cases if i look at the successor of a it has a right child and in this case the right child of a is the successor but that's not always the case i don't have a good example but if i had another node here let's call it g uh the successor of a is actually g right because all of these items come after a in the order but which one comes first the leftmost leaf okay that's the problem we just solved so if a has a right child what we want is the leftmost leaf the first thing in that subtree the right subtree right child sub tree so this is case one if uh node.right so if we have a right child then what we want is subtree first of the right child great we can reduce to this other operation but what if the node doesn't have a right child so for example it could be a leaf say we're taking the successor of i mean it doesn't have to be a leaf could be f which has no children it could be d which has one child but no right child so what's the successor of f well it's d which in this case is the parent but it's not always for example if we do successor of e its parent is actually earlier in the order because e was a right child here f was a left child and so its parent was after successor of d happens to be b because uh it's per it was the left child of its parent okay so that seems like the easy case if we're the left child of our parent then our successor is our parent okay basing on this small example but we can argue it generally in a moment what's the successor of e uh well it's not b because that comes earlier in fact all the things in this in b sub tree come earlier or equal to e um so we have to keep going up and then it turns out the successor of e is a because this subtree was the left child of a because b was a left child with a so the general strategy is walk up the tree until we are we we go up a traversal whose reverse direction would be left okay so um walk up the tree when i say walk up i mean node equals node.parent iteration until we go up a left branch so this would mean that node before we do the change node equals node.parent node.parent.left okay so we can check that and then after we do that traversal that parent is exactly the node we're looking for okay why is this true in general let me draw a more generic picture so we're starting at some node and let's say its parent is to the right so it comes later in the order for a while sorry get this backwards we're doing successor so it goes to left for a while so these are all these nodes will come earlier in the order because by the definition everything in the right subtree comes after and at some point we have a parent that's to the right meaning this node was the left child of this parent and that node by definition will come after all of the nodes in here and could there be anything in between node and this uh this parent grandparent ancestor only if there was something in this subtree and we're in the case here where there is no right subtree of our original node so this this is where all the nodes in between node and here would be but there aren't any and therefore this is the successor so that's sort of the general argument why this works i see a question yeah placed into the traverse order so the traversal order is never explicitly computed what we're taught it's always implicit we can't afford to maintain this as say an array this is just in our heads maybe i will draw it with a cloud around it we're just thinking this okay it's not in the computer explicitly in the computer all we store is this and the reason is this is expensive we don't we can't maintain an array of things and be able to insert in the middle whereas this is cheap i can afford to maintain this structure and do all these things and so the reason we're talking about these operations is they're letting us manipulate the order or in this case letting us iterate through the order so this was an algorithm for iterating through the entire order but that takes linear time this was getting started in the order find me the first first thing the order and this was given one node find me the next one how long do these operations take right at most the height of the entire tree in fact it's going to be the depth of that first node but in the worst case that's the height of the entire tree in general all of these operations are going to be order h we need to think about it in each case except for this one which is order n so iterating through the whole thing um this in this case we're just calling subtree first so that takes order h time here we're walking up the tree instead of down but that's going to cost exactly the height of the node we happen to stop early but worst case order h for all this all the operations we consider today we just want to get an order h bound and later we will bound h so the point is these are fast if h is small like log n these are almost instantaneous whereas if i had to update the explicit traversal order say as an array i would have to spend linear time every time i make a change and yes it would be fast to do successor if i had this stored explicitly but maintaining it would be impossible maintaining it efficiently would be impossible question questions yes okay cool um so these were queries where i want to follow see what's what's next in the traversal sequence now let's talk about actually changing the traversal sequence so these are insert and delete operations these will correspond roughly to insert at or delete at but they're not quite we're not quite in sequence world yet instead we're going to focus on inserting or deleting in the middle of a subtree so i'm going to have two nodes so the in the traversal order so node already exists in the tree new is a new node that does not yet exist in the tree hence i call it new and what i'd like to do is insert new right after node and there's a symmetric operation which is insert before it will be implemented almost identically so we'll just focus on after so i want to insert this new node in the traversal order which again is in our heads this is all in in our thought bubble that's what we want to achieve and we have to do it by manipulating this tree and however we change the tree it defines a new traversal order so maybe let's do an example first actually i probably want this universal order keep track of that so uh let's say the first thing we want to do uh is insert g before e i want to illustrate both of the operations insert h after e a okay um so insert g before e so conceptually what we want to do is insert g here and the way so we're given the node e and we're given a sort of empty node i mean a node that just contains g it doesn't have any pointers yet and we would like to put it before e where should i put it left child all right so that's this is an easy case if i'm trying to insert before and there's no left child stick it there if i'm trying to insert after and there's no right child stick it there easy so let me write down case one so here we're inserting after so if there's no uh right child put new there okay i'm using informal language here putting this new node there b instead of writing for example node.write equals new because that's only one operation you need to do one thing you would do is set node.write equals to new but you also have to set new's parent to be node.write so instead of worrying about those two pointer changes because we always do bi-directional pointer changes i'm just going to use pseudocode and then in recitation you'll see actual python code that does all this uh so then there's the other case so that should be the second example insert h after a right insert h after a so we already have a node after a in the right child in this right subtree so where do i want to put h relative to a well it should be to the right of a but it should be before c it should be to the left of c so that would mean we want to put it here okay in this case it was pretty easy because this tree was small where do i want to put it in general well wherever subtree first tells me to put it right subtree first is going to give me the successor these are all kind of parallel um we're in the case now where our node has a right child and then successor tells us where the successor is it is the first node which is the leftmost descendant in the right subtree of the node okay a lot of pointers to follow in that sentence but it's clear in the picture so this in this case we had node and there was no right child so we just added new to be its right child okay in the other case we had a right child so here is node there's uh there's this node here node.right which now we're supposing exists and it defines a whole subtree there's this one which is the first node in the traversal order of the subtree also known as the successor of node so i'll call this successor of node in the current traversal order but of course we'd like to make new the new successor of the node so where does it go here we want to add it as a left child to the old successor okay so put uh node as so take the successor and if you look at the code for successor we're in this case so we know it will just call subtree first of node.right and remember subtree first went left as much as it possibly could so what that means is this successor node is guaranteed to not have a left child right because it was defined by going right once and then going left as much as you could so there's no more left which means we can make one more left just add new there and we're done now if you look at the traversal order it will be node then new then the old successor and then the rest of that subtree okay it's kind of cool in all cases uh i mean this was constant time here we spent constant time after we called successor successor costs order h time so this is order h new new okay put new there clear okay that was insertion let's do deletion get the spec right and the example all of these are going to have two cases uh so let me oh i didn't update so now h is after a so it should be like this you can check the new traverse order of this tree is exactly that next i'm going to do a couple of deletions let's delete f first and then we're going to well this is confusing and then we're going to delete a so where's f we're supposing we're given a pointer to f this node well it's a leaf so if i want to delete it i just erase it easy leaves are easy to delete there's no work to do so what that means is i'm removing the pointer from d to f okay we just erase that guy uh okay now here's a trickier one suppose i want to delete the root of the tree this is kind of the hardest case but in general it would be somewhere in between leaf and root so if i want to delete a if i just erased it then suddenly there are these pointers to nowhere and i disconnect the tree into two parts i don't want to do that i need to keep my tree connected so i'm going to play this trick which is i forget if i use successor or predecessor predecessor so i'm going to uh look at a we already have defined successor and there by predecessor so i'm going to look at the predecessor of a which is e you can check that here the one before a is e this is in the left subtree uh find me the rightmost item keep going right until i can't that's e so now these guys are adjacent in the order and i'm about to remove a from the order so i can momentarily cheat and swap their labels i'm going to erase a and e here and put e after a why because it moves a down in the tree and if i get to the leaf i'm done so i'm not quite done because this is not a leaf so again i look at a's predecessor it's now g predecessor we hope is always in the uh farther down in the tree and then i swap a with g okay i have preserved the traversal order except where a falls just by moving a earlier in the order here and now a is a leaf and i can erase it okay so that's what we're going to follow now in actuality it's a little tricky sometimes we need to use predecessors sometimes we need to use successor okay so the cases are if the node is a leaf just detach it from the parent easy that's sort of our base case in the recursion otherwise there are two cases if so if we're not a leaf that means we have a left child or a right child or both both is going to be the easy case but in general i have either there's a left child or there's a right child in either case i'm going to be happy so i don't need a both case uh okay so what do i do in if i have a left child that guarantees to me that if the node's predecessor is inside that left sub-tree which means it's lower in the tree if i didn't have a left child the predecessor would actually be higher in the tree and i don't want to go higher okay so if i have a left child i know the predecessor is lower and so i'm going to swap my item the contents of my node with my predecessor's item and then i'm going to recursively delete the predecessor okay that's the case that we looked at in this code in this example because we always had a left child if we have a right child but no left child we just do the reverse we swap with our successors item and then delete the successor in either case we're going down and so if we start at some node like the route every time we do this operation we're walking down and then we're walking down and in general we'll keep walking down resuming where we left off which means total amount of time we spend is proportional to the height of the tree in the worst case question right so e didn't used to have a right child so we're changing identities of nodes when we do this because we uh this that we didn't actually move this circle the circle stayed in place and what we changed was the item that was stored in that circle so whether you call this node e or a it doesn't really matter it is just the root note okay so we're gonna play a lot of these tricks of moving the items around so far we hadn't been doing that we've just been creating nodes and placing them somewhere but now we're in this delete operation is the first time where we're changing what's stored in the nodes but we still can define the traversal order right the traverse order of this tree is dbgehc which should be what we get here if i delete f and a and sorry can f trees will not preserve connections that's just the name of the game we are we have to allow this otherwise we can't do anything that's the short version okay okay in the last few minutes let me talk about how we take these trees and implement a set or sequence okay i've already alluded to this so for a sequence we just make the traversal order equal to the the order that we're trying to represent the sequence order and if we're trying to source set items with keys we're going to make the traversal order equal to ordered by increasing key increasing item key some sense that's it but then we need to think about how do we implement all of these operations so maybe most enlightening is for starters is finding a key in a tree so this is going to correspond to binary search if i'm searching for a key let's say i'm searching for g's key and i know this may be hard in this example maybe i'll replace these all with numbers so i can think about key values okay so let's say 1 7 12 17 19 and 23. this is now in key order if you think of the traversal order the property is that all the keys in the left subtree of the root are less than the root and the root is less than all the keys in the right subtree and recursively all the way down this is something called the binary search tree property bst property these here we're calling them binary tree sets or set binary trees but they're also known in the literature as binary search trees term you may have heard before so this is a special case of what we're doing where we're storing the keys in order and then if i want to search for a key like uh 13 i compare that key with the root i see oh it's not equal and it's to the left because it's less than 17. so 13 is left of here 13 is right of 7 13 is right of 12 and so i know that this is where 13 would belong but there's no right child there and so i know in find i just returned nothing if i was doing find previous i would return this note because i have tried to go to the right the last time before i fell off the tree i was trying to go to the right and therefore that last note i had was the previous item if i was trying to define next what would i do i would just take this node and compute its successor which we already know how to do and that happens to be the root okay so now i can do these inexact searches when i do find previous and find next when i fall off the tree i find either the previous or the next and then with predecessor or successor i can find the other one okay so that's how we can do find and find previous and find next to do uh sequences we need a little bit more work we'll do that next time you